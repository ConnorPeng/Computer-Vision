{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 132
    },
    "colab_type": "code",
    "id": "fiK4QNWKDvWJ",
    "outputId": "0e498e6b-9c67-40e3-ff46-837f888d8377"
   },
   "source": [
    "# Scene Recognition with Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8-TUO3hQhZ-2"
   },
   "source": [
    "## Outline\n",
    "In this project, we will use *convolutional neural nets* to classify images into different scenes.\n",
    "\n",
    "Basic learning objectives of this project:\n",
    "1. Construct the fundamental pipeline for performing deep learning using PyTorch;\n",
    "2. Understand the concepts behind different layers, optimizers.\n",
    "3. Experiment with different models and observe the performance.\n",
    "\n",
    "The starter code is mostly initialized to 'placeholder' just so that the starter\n",
    "code does not crash when run unmodified and you can get a preview of how\n",
    "results are presented.\n",
    "\n",
    "## Compute Requirements\n",
    "\n",
    "This project is doable without a GPU, but a GPU makes the process much more faster and frustration free.\n",
    "\n",
    "You can try out Google Colab to run this notebook. These are the steps we follow:\n",
    "1. Upload this notebook to google colab\n",
    "2. Zip all the components in the project directory and upload it to the colab runtime\n",
    "3. Unzip the uploaded zip using ```!unzip -qq <uploaded_file>.zip -d ./```\n",
    "\n",
    "Remember to download all the files saved and changes to code you made on the colab.\n",
    "\n",
    "Note that we will not be actively supporting issues with Google colab. Please take help from fellow students and use the internet to solve the issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v3KVmDW-TdjI"
   },
   "source": [
    "## Dataset\n",
    "You would have already stored the dataset in the ```data``` folder. It is the same data you have used in PS5. It has two subfolders: ```train``` and ```test```. Go through any of the folder and find there you will find the folders with scene names like *bedroom*, *forest*, *office*. These are the 15 scenes that we want our model to predict given an RGB image. You can look into folder for each scene to find multiple images. All this data is labelled data provided to you for training and testing your model.\n",
    "\n",
    "**Let's start coding now!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BFVeSYKzTdjK"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8QRsVzCGTdjB"
   },
   "outputs": [],
   "source": [
    "# uncomment for running on colab\n",
    "# !unzip -qq proj6_colab.zip -d ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2kTYp67dhZ_D"
   },
   "outputs": [],
   "source": [
    "# flag to modify paths to run better on Colab; change it to true if you want to run on colab\n",
    "use_colab_paths = False "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DikW12-RhZ_J"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g1dqr6qSBpE2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from proj6_code.runner import Trainer\n",
    "from proj6_code.optimizer import compute_quadratic_loss, get_optimizer, gradient_descent_step\n",
    "from proj6_code.simple_net import SimpleNet\n",
    "from proj6_code.simple_net_dropout import SimpleNetDropout\n",
    "from proj6_code.my_alexnet import MyAlexNet\n",
    "from proj6_code.data_transforms import get_fundamental_transforms, get_data_augmentation_transforms\n",
    "from proj6_code.stats_helper import compute_mean_and_std\n",
    "from proj6_code.vis import visualize\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CG3e0869TdjS"
   },
   "outputs": [],
   "source": [
    "from proj6_code.proj6_unit_tests.test_base import verify\n",
    "from proj6_code.proj6_unit_tests.test_stats_helper import test_mean_and_variance\n",
    "from proj6_code.proj6_unit_tests.test_data_transforms import test_fundamental_transforms\n",
    "from proj6_code.proj6_unit_tests.test_dl_utils import test_predict_labels, test_compute_loss\n",
    "from proj6_code.proj6_unit_tests.test_simple_net import test_simple_net\n",
    "from proj6_code.proj6_unit_tests.test_simple_net_dropout import test_simple_net_dropout\n",
    "from proj6_code.proj6_unit_tests.test_my_alexnet import test_my_alexnet\n",
    "from proj6_code.proj6_unit_tests.test_checkpoints import test_simple_net_checkpoint\n",
    "from proj6_code.proj6_unit_tests.test_optimizer import test_compute_quadratic_loss, test_gradient_descent_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GjE0jIc5BpFN"
   },
   "outputs": [],
   "source": [
    "is_cuda = True\n",
    "# torch.cuda.is_available() checks if there is a GPU on the system and it has CUDA drivers installed\n",
    "# CUDA helps accelerate operations in Pytorch\n",
    "is_cuda = is_cuda and torch.cuda.is_available() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IKRS4gvZTdji"
   },
   "outputs": [],
   "source": [
    "data_base_path = '../data/' if not use_colab_paths else 'data/'\n",
    "model_base_path = '../model_checkpoints/' if not use_colab_paths else 'model_checkpoints/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "1QoVOsGwhZ_j",
    "outputId": "433432c2-bfe7-4d68-93bd-4579415578cf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(os.listdir(data_base_path))\n",
    "print(os.listdir(model_base_path))\n",
    "\n",
    "# TODO: check that these outputs are as per expectation. It will save a lot of time in debugging issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nulEn5fzTdjs"
   },
   "source": [
    "To train a network in PyTorch, we need 4 components:\n",
    "1. **Dataset** - an object which can load the data and labels given an index.\n",
    "2. **Model** - an object that contains the network architecture definition.\n",
    "3. **Loss function** - a function that measures how far the network output is from the ground truth label.\n",
    "4. **Optimizer** - an object that optimizes the network parameters to reduce the loss value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mA7pA3FWhZ_I"
   },
   "source": [
    "## 1 Dataset\n",
    "The dataset is in the ```data``` folder. It has two subfolders: ```train``` and ```test```. Go through any of the folder and find there you will find the folders with scene names like *bedroom*, *forest*, *office*. These are the 15 scenes that we want our model to predict given an RGB image. You can look into folder for each scene to find multiple images. All this data is labelled data provided to you for training and testing your model.\n",
    "\n",
    "**Let's start coding now!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B027mwlKTdjt"
   },
   "source": [
    "One crucial aspect of deep learning is to perform data preprocessing. In DL, we usually *normalize* the dataset and perform some *transformations* on them. The transformations can either help the inputs be compatible with the model (say our model only works on 500x500 images and we need all input to be cropped/scaled to this size) or help in data-augmentation to improve performance (more on this later).\n",
    "\n",
    "\n",
    "### 1.1 Compute mean and standard deviation of the dataset\n",
    "In this project we are going to \"zero-center\" and \"normalize\" the dataset so that each entry has zero mean and the overall standard deviation is 1. To do this, we will compute the mean and variance of the actual dataset first. To perform actual normalization, we will use a transform from Pytorch. \n",
    "\n",
    "**TODO 1**:  fill in the `compute_mean_and_std()` in `stats_helper.py` to compute the **mean** and **standard deviation** of both training and test set combined.\n",
    "\n",
    "Debug tip: If you face an error from StandardScaler about attribute not found, please check that the paths are correct and your code actually finds some images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vWA_2UbjBpFd",
    "outputId": "c84201a5-d7c9-4e0e-9b42-5fb784034556"
   },
   "outputs": [],
   "source": [
    "print(\"Testing your mean and std computation: \", verify(test_mean_and_variance))\n",
    "dataset_mean, dataset_std = compute_mean_and_std(data_base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xixFr8CDBpFn",
    "outputId": "e5da02f4-ac00-4443-8144-4e4e72bb1555"
   },
   "outputs": [],
   "source": [
    "print('Dataset mean = {}, standard deviation = {}'.format(dataset_mean, dataset_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-2TeGbrQBpFu"
   },
   "source": [
    "### 1.2 Data Loader\n",
    "\n",
    "We'll have stored our input images in a specific format: each class name is a folder, with images belonging to that class inside the folder. This specific choice of storage scheme enables us to directly use the [`ImageFolder` ](https://pytorch.org/vision/stable/datasets.html#imagefolder) dataset from Pytorch.\n",
    "\n",
    "We'll use the `ImageFolder` to make two loaders, for train and test split respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = ImageFolder(root=os.path.join(data_base_path, 'train'))\n",
    "test_loader = ImageFolder(root=os.path.join(data_base_path, 'test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of entries in training set: {len(train_loader)}\")\n",
    "print(f\"Number of entries in test set: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing some examples from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 100\n",
    "\n",
    "image, class_label = train_loader.__getitem__(idx)\n",
    "plt.figure()\n",
    "plt.imshow(image)\n",
    "plt.title(f'Image at index {idx}. Class Label {class_label}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 300\n",
    "\n",
    "image, class_label = train_loader.__getitem__(idx)\n",
    "plt.figure()\n",
    "plt.imshow(image)\n",
    "plt.title(f'Image at index {idx}. Class Label {class_label}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EIq75D2CTdkC"
   },
   "source": [
    "### 1.3 Data transforms\n",
    "In this section, we will construct some fundamental transforms to process RGB images into torch tensors, which we can provide as input to our model.\n",
    "\n",
    "1. Resize the input image to the desired shape\n",
    "2. Convert to a single channel grayscale image (ImageFolder will read the image as a color image with 3 channels, even though the colors are all gray).\n",
    "3. Convert it to a tensor\n",
    "4. Normalize them based on the mean and standard deviation already computed in 1.1.\n",
    "\n",
    "All these operations can be done using [torchvision's transforms](https://pytorch.org/vision/stable/transforms.html). You'll need to write one line for each operation.\n",
    "\n",
    "**TODO 2:** For this part, complete the function `get_fundamental_transforms()` in `data_transforms.py` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZoAaL11nTdkD",
    "outputId": "e95d0343-9107-462b-aebe-2f6990efdd08"
   },
   "outputs": [],
   "source": [
    "print(\"Testing your fundamental data transforms: \", verify(test_fundamental_transforms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5sWOnZmNTdkJ"
   },
   "source": [
    "## 2 Model Architecture and Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_size = (64,64) # input size to use for this section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bg59TFXHTdkL"
   },
   "source": [
    "### 2.1 SimpleNet Model\n",
    "\n",
    "The data is ready! Now we are preparing to move to the actual core of deep learning: the architecture. To get you started in this part, simply define a **2-layer** model in the `simple_net.py`. Here by \"2 layers\" we mean **2 convolutional layers**, so you need to figure out the supporting utilities like ReLU, Max Pooling, and Fully Connected layers, and configure them with proper parameters (such as kernel size, padding, etc) such that the output from a layer is compatible as input to the next layer.\n",
    "\n",
    "You may refer the image *simplenet.jpg* in the base folder for a sample network architecture (it's the architecture TAs used in their implementation and is sufficient to get you pass Part 1). In that image, the layers in use are written at the bottom, and the blocks show the shape of features after each layer.\n",
    "\n",
    "Note that the input image will be shaped as (N, C, H, W) where N are the number of images in a batch, C is the number of color channels in the image, H is the height, and W is the width.\n",
    "\n",
    "**TODO 3**: Do the following in ```simple_net.py```:\n",
    "- Initialize ```self.conv_layers```\n",
    "- Initialize ```self.fc_layers```\n",
    "- Write the forward function\n",
    "\n",
    "Leave the ```self.loss_criterion = None``` for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jvVL-ap0BpFx",
    "outputId": "d97819e7-741e-4d37-82ea-8351dd103dff"
   },
   "outputs": [],
   "source": [
    "print(\"Testing your SimpleNet architecture: \", verify(test_simple_net))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o_YLUulTTdkX"
   },
   "source": [
    "### 2.2 Output prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pNBpN4ofTdkZ"
   },
   "source": [
    "Let's see what out model's forward function produces for a sample input, and how it relates to classification. Pytorch's convolution and FC layers are initialized with random weights. So we should not expect any useful output without any training.\n",
    "\n",
    "We will use a data-point from a new `ImageFolder` object with the transformations we have defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9IW3f_SgTdkc"
   },
   "outputs": [],
   "source": [
    "simple_model = SimpleNet()\n",
    "\n",
    "train_loader = ImageFolder(root=os.path.join(data_base_path, 'train'), \n",
    "                           transform=get_fundamental_transforms(inp_size, dataset_mean, dataset_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OyQDxArjTdkg"
   },
   "outputs": [],
   "source": [
    "# get the 0th sample\n",
    "sample_image, sample_label = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "myJ9kcqUTdkm",
    "outputId": "ec53cd08-979d-41d7-bc7b-07eca46ed064"
   },
   "outputs": [],
   "source": [
    "print('Input image shape = ', sample_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "colab_type": "code",
    "id": "bvHtwSATTdkr",
    "outputId": "ea02c24c-e16c-4af7-e3d1-5b8dc25cf280"
   },
   "outputs": [],
   "source": [
    "#show the image\n",
    "fig, axs = plt.subplots()\n",
    "axs.imshow(sample_image.squeeze().numpy(), cmap='gray')\n",
    "axs.axis('off')\n",
    "axs.set_title('Sample image (Target label = {})'.format(sample_label))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b0XEqQaNTdkw"
   },
   "outputs": [],
   "source": [
    "# run the image through the model\n",
    "sample_model_output = simple_model(sample_image.unsqueeze(0)).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "2v9WUSlbTdkz",
    "outputId": "965375e6-08dd-48da-c4cf-ce3ccef31e2c"
   },
   "outputs": [],
   "source": [
    "print(sample_model_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tCtiLVKKTdk3"
   },
   "source": [
    "We have a 15-dimensional tensor as output, but how does it relate to classification?\n",
    "\n",
    "We first convert the this tensor into a probability distribution over 15 classes by applying the [Softmax](https://en.wikipedia.org/wiki/Softmax_function) operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Ssu7W4jTdk4"
   },
   "outputs": [],
   "source": [
    "sample_probability_values = torch.nn.functional.softmax(sample_model_output, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "4BXWrwl0Tdk9",
    "outputId": "eb041618-7ba1-4ded-ce43-5eb8a395ac86"
   },
   "outputs": [],
   "source": [
    "print(sample_probability_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sum of probability values: \", torch.sum(sample_probability_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iTABRuGpTdlD"
   },
   "source": [
    "The prediction of the model will be the index where the probability distribution is the maximum. Convince yourself that the argmax-operation on *sample_model_values* is the same as the argmax-operation on *sample_probability_values*. Hence for prediction, we can take the argmax on the model output directly without applying a softmax. Also, you can check that the sum of softmax values is 1 and hence they are valid probability values.\n",
    "\n",
    "**TODO 4:** Complete the ```predict_labels()``` function in ```dl_utils.py```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w3j6LNUyTdlD"
   },
   "source": [
    "## 3 Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d2mIs5sQTdlE"
   },
   "source": [
    "We have written a model which takes in a tensor for an image and produces a 15 dimensional output for it. We saw in the previous section on how the output relates to the prediction and probability distribution. But how do we quantify the performance of the model, and how do we use that quantification to form an objective function which we can minimize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1esn_cCXTdlE"
   },
   "source": [
    "Ideally, we would want the probability function to have value 1 for the target *sample_label* and value 0 for the remaining class indices. To penalize the deviation between the desired probability distribution and the model-predicted distrtibution, we use the KL-divergence loss or the cross-entropy loss. Please refer to [this stackexchange post](https://datascience.stackexchange.com/questions/20296/cross-entropy-loss-explanation) for a good explanation and derivation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SvSEgfOBTdlF"
   },
   "source": [
    "**TODO 5:** Assign a loss function to ```self.loss_criterion``` in ```simple_net.py```. Note that we have not done a softmax operation in the model's forward function and choose the [appropriate loss function](https://pytorch.org/docs/stable/nn.html#loss-functions). In this TODO, you just have to assign the correct loss function in the model. \n",
    "\n",
    "**TODO 6:** Complete the ```compute_loss()``` function in ```dl_utils.py``` to use the model's loss criterion and compute the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u9Y3TEv7TdlG"
   },
   "outputs": [],
   "source": [
    "simple_model = SimpleNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "Y2Lu0S_ETdlK",
    "outputId": "584fd9e2-1fbf-47c7-dc18-81e70ebfc2c3"
   },
   "outputs": [],
   "source": [
    "print(simple_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "hbcEPDN0TdmF",
    "outputId": "4545c9ed-1dcb-45fe-eaba-c51d21163bc1"
   },
   "outputs": [],
   "source": [
    "print(\"Testing your model prediction: \", verify(test_predict_labels))\n",
    "print(\"Testing your loss values: \", verify(test_compute_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LKQCj596TdlQ"
   },
   "source": [
    "## 4 Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CB0oPQtVTdlR"
   },
   "source": [
    "### 4.1 Manual gradient descent using Pytorch's autograd\n",
    "\n",
    "Till now, we have defined the model, and designed a loss function which is a proxy for *good* classification. We now to optimize the weights of the network so that the loss function is minimized.\n",
    "\n",
    "Pytorch is a very useful library for deep learning because a lot of tensor operations and functions support the flow of gradients. This feature is called [autograd](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html). This functionality lets use use gradient based optimization techniques like gradient descent without writing a lot of code.\n",
    "\n",
    "Let us first understand how we can access the gradients.\n",
    "\n",
    "### Define an objective function (equivalent to the loss we defined in Section 3)\n",
    "Suppose we have a simple objective function that looks like:\n",
    "$$ L(w) =  w^2 - 10w + 25 $$\n",
    "\n",
    "This is a convex problem, and we know that the loss $L$ is minimized for $w=5$, and we can obtain this in closed form.\n",
    "\n",
    "But let us use gradient descent to obtain the solution in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO 7:** Complete `compute_quadratic_loss` in `optimizer.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JLu-7PG1TdlS"
   },
   "outputs": [],
   "source": [
    "print(\"Testing your quadratic loss function: \", verify(test_compute_quadratic_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YPVWOjo6TdlW"
   },
   "source": [
    "Let's compute the loss at w = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pbVokXpUTdlX",
    "outputId": "666d20f0-39b9-4719-fe4c-338e2e117534"
   },
   "outputs": [],
   "source": [
    "w = torch.tensor([0.0], requires_grad=True) # we mark this tensor to require gradient so that the computation graph\n",
    "# can account for it\n",
    "\n",
    "loss = compute_quadratic_loss(w)\n",
    "\n",
    "print('w={:.4f}\\tLoss={:.4f}'.format(w.detach().numpy().item(), loss.detach().numpy().item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AabZ-6MnTdla"
   },
   "source": [
    "Now we can do a backward pass of the gradients to get the gradient of loss w.r.t w. Now we need to calculate the gradients with regard to the weights and biases using backprop. It will be very painful if we do it manually, but thankfully, in PyTorch we can have everything covered with autograd, which only needs a simple call of **.backward()** on our loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jcrIh9P3Tdlb",
    "outputId": "2f5b1efe-ece3-433e-e583-3f3e204f3adf"
   },
   "outputs": [],
   "source": [
    "# perform a backward pass on loss (we need to retain graph here otherwise Pytorch will throw it away)\n",
    "loss.backward(retain_graph=True)\n",
    "\n",
    "print(w.grad.data)\n",
    "\n",
    "# manually zero out the gradient\n",
    "w.grad.zero_()\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wAPF2cBATdlf"
   },
   "source": [
    "Does this gradient match with the one you compute manually?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qmd3JnxzTdli"
   },
   "source": [
    "With the gradients, we can update the weights and biases using gradient descent:\n",
    "$$w_{k+1}=w_{k} - \\alpha\\frac{\\partial L}{\\partial w_k}$$\n",
    "where $w$ is the parameter we are updating, $\\alpha$ is the learning rate, and $\\frac{\\partial L}{\\partial w_k}$ is the gradient at step $k$. You can learn more about gradient descent [here](https://en.wikipedia.org/wiki/Gradient_descent) and [here](https://developers.google.com/machine-learning/crash-course/reducing-loss/gradient-descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO 8:** Implement a single step of gradient descent in function `gradient_descent_step` in `optimizer.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing gradient descent step: \", verify(test_gradient_descent_step))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uMEZ9eHuTdlm"
   },
   "source": [
    "Let's take one step of the gradient descent and check if the the loss value decreased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0BuBQHZwTdln"
   },
   "outputs": [],
   "source": [
    "# set learning rate\n",
    "lr = .03\n",
    "\n",
    "loss = compute_quadratic_loss(w)\n",
    "gradient_descent_step(w, loss, lr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yIWP3Tv4Tdlq",
    "outputId": "ba32ccb8-73d9-4a1d-ab6f-4822df3eb4eb"
   },
   "outputs": [],
   "source": [
    "loss = compute_quadratic_loss(w)\n",
    "print('w={:.4f}\\tLoss={:.4f}'.format(w.detach().numpy().item(), loss.detach().numpy().item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Mb4IdocTdlv"
   },
   "source": [
    "Looks like it's been optimized!\n",
    "\n",
    "Now let's run a few more updates and see where we can get!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "colab_type": "code",
    "id": "FTfmRlc0Tdlv",
    "outputId": "0b111b50-90d6-47a2-b870-c05c2fc1b88a"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "for i in range(200):\n",
    "    loss = compute_quadratic_loss(w)\n",
    "    if not (i+1)%10:\n",
    "        print('Iteration {}: w={:.4f}\\tLoss={:.4f}'.format(\n",
    "            i+1, w.detach().numpy().item(), loss.detach().numpy().item()))\n",
    "        \n",
    "    gradient_descent_step(w, loss, lr) \n",
    "        \n",
    "print('\\noptimization takes %0.3f seconds'%(time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CTFEo_JMTdlz"
   },
   "source": [
    "Seems that it's doing a great job training our model! The loss now has decreased significantly to a pretty small value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZMtBy2JvTdl0"
   },
   "source": [
    "### 4.2 Optimization using Pytorch's gradient descent optimizer\n",
    "\n",
    "Now let's see how we can simplify this using the `torch.optim` package from PyTorch. You can see that using optimizer from `torch.optim` package can achieve the same results with a lot less code from our side. Also, there are many features available over the vanilla gradient descent. Let's use the Stochastic Gradient Descent (SGD) optimizer available in Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "colab_type": "code",
    "id": "YKb3ngxtTdl1",
    "outputId": "b444730f-5b89-4ecb-c5c5-95a93833d851"
   },
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "\n",
    "# define parameters we want to optimize\n",
    "w = torch.tensor([0.0], requires_grad=True)\n",
    "\n",
    "optimizer = SGD([w], lr=lr)\n",
    "\n",
    "start = time.time()\n",
    "for i in range(200):\n",
    "    loss = compute_quadratic_loss(w)   \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if not (i+1)%10:\n",
    "        print('Iteration {}: w={:.4f}\\tLoss={:.4f}'.format(\n",
    "            i+1, w.detach().numpy().item(), loss.detach().numpy().item()))\n",
    "        \n",
    "print('\\noptimization takes %0.3f seconds'%(time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4IsnddUCTdl5"
   },
   "source": [
    "### 4.3 Setting up the optimizer for SimpleNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OxeVYy1bTdl6"
   },
   "source": [
    "**TODO 9:** **initialize the following cell with proper values for learning rate and weight decay** \n",
    "\n",
    "**Note:** There is nothing to do in this TODO for the first pass. You'll train the model with these values and it will be bad. Then you can come back here and tune the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V2cwtK5PBpF7"
   },
   "outputs": [],
   "source": [
    "# TODO: add a decent initial setting and tune from there\n",
    "optimizer_config = {\n",
    "  \"optimizer_type\": \"adam\",\n",
    "  \"lr\": 1e-3,\n",
    "  \"weight_decay\": 1e-5\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q3pyzj8KTdl_"
   },
   "source": [
    "We will now set up a utility function to define an optimizer on the loss for a model.\n",
    "\n",
    "**TODO 10:** complete the ```get_optimizer()``` function in ```optimizer.py```. The helper function accepts three basic configurations as defined below. Any other configuration is optional. *SGD* optimizer type should be supported, anything else is optional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Aa-D7Q_TdmA"
   },
   "source": [
    "<span style=\"color:red\">TA TODO: corrupt the values above before releasing</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P0CrYZa4BpGE"
   },
   "outputs": [],
   "source": [
    "optimizer = get_optimizer(simple_model, optimizer_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3b8cjmrSTdmK"
   },
   "source": [
    "## 5 Training SimpleNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DBrJnj2tTdmL"
   },
   "source": [
    "We have completed all the components required to train the first model for this course. Let's pass in the model architecture, optimizer, transforms for both the training and testing datasets into the trainer, and proceed to the next cell to train it. If you have implemented everything correctly, you should be seeing a decreasing loss value.\n",
    "\n",
    "**Note** in this project, we will be using the test set as the validation set (i.e. using it to guide our decisions about models and hyperparamters while training). In actual practise, you would not interact with the test set until reporting the final results.\n",
    "\n",
    "**Note** that your CPU should be sufficient to handle the training process for all networks in this project, and the following training cells will take less than 5 minutes; you may also want to decrease the value for `num_epochs` and quickly experiment with your parameters. The default value of **30** is good enough to get you around the threshold for Part 1, and you are free to increase it a bit and adjust other parameters in this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UiGOvPJfBpGO"
   },
   "outputs": [],
   "source": [
    "# re-init the model so that the weights are all random\n",
    "simple_model = SimpleNet()\n",
    "optimizer = get_optimizer(simple_model, optimizer_config)\n",
    "\n",
    "trainer = Trainer(data_dir=data_base_path, \n",
    "                  model = simple_model,\n",
    "                  optimizer = optimizer,\n",
    "                  model_dir = os.path.join(model_base_path, 'simple_net'),\n",
    "                  train_data_transforms = get_fundamental_transforms(inp_size, dataset_mean, dataset_std),\n",
    "                  test_data_transforms = get_fundamental_transforms(inp_size, dataset_mean, dataset_std),\n",
    "                  batch_size = 32,\n",
    "                  load_from_disk = False,\n",
    "                  cuda = is_cuda\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 555
    },
    "colab_type": "code",
    "id": "paNLyU5cBpGX",
    "outputId": "e8506469-b4e5-4aa6-9423-8235b96068ab"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "simple_net_start = time.time()\n",
    "trainer.train(num_epochs=30)\n",
    "simple_net_end = time.time()\n",
    "print(\"The training time taken for simple net is {:.9f}\".format(simple_net_end-simple_net_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jv1T8xv2TdmR"
   },
   "source": [
    "Now let's have your model predict on some examples and see how well it performs qualitatively. You should try the following cell multiple times to understand whats happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "colab_type": "code",
    "id": "thCGob3JTdmR",
    "outputId": "1629bc1c-8972-46ce-8cdb-0b420c0337cb"
   },
   "outputs": [],
   "source": [
    "# visualize train split\n",
    "print(\"Examples from train split:\")\n",
    "visualize(simple_model, 'train', get_fundamental_transforms(inp_size, dataset_mean, dataset_std), data_base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "colab_type": "code",
    "id": "QQbkZhjlTdmU",
    "outputId": "d227b903-2c31-4a5e-b3b2-8ade627c0791"
   },
   "outputs": [],
   "source": [
    "# visualize test split\n",
    "print(\"Examples from test split:\")\n",
    "visualize(simple_model, 'test', get_fundamental_transforms(inp_size, dataset_mean, dataset_std), data_base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "colab_type": "code",
    "id": "z0b_WwJhBpGf",
    "outputId": "3d80145a-dd14-40fd-f30c-9f47ac0f4d75",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainer.plot_loss_history()\n",
    "trainer.plot_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8epn0IBmBpGn",
    "outputId": "23555727-ed23-490d-ddfc-783fa439101d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_accuracy = trainer.train_accuracy_history[-1]\n",
    "validation_accuracy = trainer.validation_accuracy_history[-1]\n",
    "print('Train Accuracy = {:.4f}; Validation Accuracy = {:.4f}'.format(train_accuracy, validation_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CQKKbNc2haCZ",
    "outputId": "8ef542c8-409c-4ed2-840f-198a711e66e1"
   },
   "outputs": [],
   "source": [
    "print('Testing simple net weights saved: ', verify(test_simple_net_checkpoint))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gWNCMmRzTdmc"
   },
   "source": [
    "After you have finished the training process, now plot out the loss and accuracy history. You can also check out the final accuracy for both training and validation data. Copy the accuracy plots and values onto the report, and answer the questions there. \n",
    "\n",
    "**TODO 11:** Obtain a **45%** validation accuracy to receive full credits for Part 1. You can go back to TODO 8 first to tune your paramters for optimization using the following tips:\n",
    "\n",
    "**Tips**:\n",
    "1. If the loss decreases very slowly, try increasing the value of the lr (learning rate).\n",
    "2. Initially keep the value of weight decay (L2-regularization) very low. Even zero is fine. Use the weight decay as the last resort.\n",
    "3. Try to first adjust lr in multiples of 3 initially. When you are close to reasonable performance, do a more granular adjustment. Do try to keep lr values less than 0.1.\n",
    "4. If you want to increase the validation accuracy by a little bit, try increasing the weight_decay to prevent overfitting. Do not use tricks from Section 6 just yet.\n",
    "\n",
    "If you still need to tweak the model architecture, you are free to do so. But remember complex models will require more time to train, and TAs could achieve ~50% accuracy with the described model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G7hE1vidBpGt"
   },
   "source": [
    "## EC1 Solving overfitting\n",
    "We have obtained a 45% accuracy on the validation data with a simple model; Feeling even better for the training accuracy right? More than 90% (if you have implemented everything correctly). But should you?\n",
    "\n",
    "Our final accuracies for training and validation data differ a lot from each other, which indicates that the model we have defined **fits too well with the training data, but is unable to generalize well on data it has not trained on**: this is often regarded as **overfitting**. In this section we are going to apply 2 techniques to tackle with it: adjusting both data and model.\n",
    "\n",
    "References:\n",
    "- https://www.cs.princeton.edu/courses/archive/spring16/cos495/slides/ML_basics_lecture6_overfitting.pdf\n",
    "\n",
    "### EC1.1 Jitter, Random Flip, and Normalization\n",
    "One common technique to increase the \"variability\" of the data is to **augment** it. Firstly, we don't have a huge amount of data, so let's \"jitter\" it; secondly, when you mirror an image of a **kitchen**, you can tell that the mirrored image is still a kitchen. \n",
    "\n",
    "**TODO 12:** finish the `get_data_augmentation_transforms()` function in `data_transforms.py`: you should first copy your existing fundamental transform implementation into this function, and then insert other which help you do the above adjustment before the fundamental ones.\n",
    "\n",
    "Tips: Try jittering the colors, and flipping the image horizontaly. These two operations wont change the scene contents. You can also try resizing and cropping. \n",
    "\n",
    "You are free to experiment with different kinds of augmentation techniques by adding new techniques or replacing existing techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ech4Y22OXOui"
   },
   "outputs": [],
   "source": [
    "inp_size = (64,64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "06cXE2wkTdmg"
   },
   "source": [
    "### EC1.2 Dropout\n",
    "\"Dropout\" is a technique commonly used to regularize the network. It randomly turns off the connection between neurons inside the network and prevent the network from relying too much on a specific neuron. \n",
    "\n",
    "References: \n",
    "- https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf\n",
    "- https://machinelearningmastery.com/dropout-for-regularizing-deep-neural-networks/\n",
    "\n",
    "**TODO 13:** finish the `simple_net_dropout.py` with your previous SimpleNet model, plus the dropout layer. Think where you want the dropout should be places: fully connected layers, conv layers, or both? Generally the layer with more number of parameters might be more prone to overfitting.\n",
    "\n",
    "If you are skipping this part, copy over the exact simple net arhcitecute. You will fail the following unit test but you can ignore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "adEPCL3QTdmi",
    "outputId": "370d27dc-8c72-4f4f-af1f-172c0a68cd15"
   },
   "outputs": [],
   "source": [
    "print(\"Testing your SimpleNetDropout architecture: \", verify(test_simple_net_dropout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "colab_type": "code",
    "id": "nlgm5eM-BpGz",
    "outputId": "d0cf7323-6648-4c3c-9410-09d04e76c40a"
   },
   "outputs": [],
   "source": [
    "simple_model_dropout = SimpleNetDropout()\n",
    "print(simple_model_dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kmmpMDRBTdmm"
   },
   "source": [
    "Similar to the previous part, **initialize the following cell with proper values for learning rate and weight decay**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "btKIvIrdBpG5"
   },
   "outputs": [],
   "source": [
    "# TODO: add a decent initial setting and tune from there\n",
    "optimizer_config = {\n",
    "  \"optimizer_type\": \"adam\",\n",
    "  \"lr\": 1e-3,\n",
    "  \"weight_decay\": 1e-5\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sI9IQVuxhaC1"
   },
   "source": [
    "<span style=\"color:red\">TA TODO: corrupt the values above before releasing</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ExoLylurBpHH"
   },
   "outputs": [],
   "source": [
    "simple_model_dropout = SimpleNetDropout()\n",
    "optimizer = get_optimizer(simple_model_dropout, optimizer_config)\n",
    "\n",
    "trainer = Trainer(data_dir=data_base_path, \n",
    "                  model = simple_model_dropout,\n",
    "                  optimizer = optimizer,\n",
    "                  model_dir = os.path.join(model_base_path, 'simple_net_dropout'),\n",
    "                  train_data_transforms = get_data_augmentation_transforms(inp_size, dataset_mean, dataset_std),\n",
    "                  test_data_transforms = get_fundamental_transforms(inp_size, dataset_mean, dataset_std),\n",
    "                  batch_size = 32,\n",
    "                  load_from_disk = False,\n",
    "                  cuda = is_cuda\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zq2__3ZQTdmt"
   },
   "source": [
    "The following cell will take longer than Part 1, as now we have more data (and more variability), and the model is slightly more complicated than before as well; however, it should finish within 10~15 minutes anyway, and the default `num_epochs` is also good enough as a starting point for you to pass this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 555
    },
    "colab_type": "code",
    "id": "-ljUl4UnBpHN",
    "outputId": "8f6c2e23-917b-483e-a4c5-01015a84d480",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainer.train(num_epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n3yOROVGTdmy"
   },
   "source": [
    "Now let's have your model predict on some examples and see how well it performs qualitatively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "732LGRJCftzL"
   },
   "outputs": [],
   "source": [
    "# # visualize train split\n",
    "print(\"Examples from train split:\")\n",
    "visualize(simple_model_dropout, 'train', get_fundamental_transforms(inp_size, dataset_mean, dataset_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jum7rI93Tdm0"
   },
   "outputs": [],
   "source": [
    "# # visualize test split\n",
    "print(\"Examples from test split:\")\n",
    "visualize(simple_model_dropout, 'test', get_fundamental_transforms(inp_size, dataset_mean, dataset_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "colab_type": "code",
    "id": "Gdh9AvHIBpHW",
    "outputId": "95f03c53-13c8-41b3-bb40-0da8262cb685",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainer.plot_loss_history()\n",
    "trainer.plot_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6SLuc3zmBpHd",
    "outputId": "095b6b08-2d99-4d85-a1f9-4273bd1546b7"
   },
   "outputs": [],
   "source": [
    "train_accuracy = trainer.train_accuracy_history[-1]\n",
    "validation_accuracy = trainer.validation_accuracy_history[-1]\n",
    "print('Train Accuracy = {:.4f}; Validation Accuracy = {:.4f}'.format(train_accuracy, validation_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IBLf3n6aTdnJ"
   },
   "source": [
    "Similar to the previous part, now plot out the loss and accuracy history. Also copy the plots onto the report, and answer the questions accordingly.\n",
    "\n",
    "**TODO 14:** Achieve **52%** validation accuracy for full credits for this part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "amh1wxlJBpHj"
   },
   "source": [
    "## EC2 Pretrained AlexNet\n",
    "You can see that after the above adjustment, our model performance increases in terms of testing accuracy. Although the training accuracy drops, now it's closer to the testing values and that's more natural in terms of performance. But we are not satisfied with the final performance yet. Our model, in the end, is still a 2-layer SimpleNet and it might be capable of capturing some features, but could be improved a lot if we go **deeper**. In this part we are going to see the power of a famous model: AlexNet.\n",
    "\n",
    "References:\n",
    "- https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ttbhBZ7CXUng"
   },
   "outputs": [],
   "source": [
    "inp_size = (224, 224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BMfz9HrpTdnO"
   },
   "source": [
    "PyTorch has provided us with pre-trained models like AlexNet, so what you want to do is to load the model first, and then adjust some of the layers such that it fits with our own dataset, instead of outputing scores to 1000 classes from the original AlexNet model.\n",
    "\n",
    "There are many reasons for using pre-trained weights instead of training AlexNet from scratch:\n",
    "1. We have a really small dataset. Alexnet has millions of parameters and will definitely overfit. The pre-trained alexnet will have access to millions of training images.\n",
    "2. We save a lot of computation.\n",
    "\n",
    "**TODO 15:** Switch to `my_alexnet.py`, and copy the network architecture and weights of all but the last fc layers from the pretrained network.\n",
    "\n",
    "After you have defined the correct architecture of the model, make some tweaks to the existing layers: **freeze** the **convolutional** layers and first 2 **linear** layers so we don't update the weights of them. More instructions are in the docstring.\n",
    "\n",
    "Note that you are allowed to add more layers/unfreeze more layers if you see fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101,
     "referenced_widgets": [
      "0b81f9c1f6bc454a87fe4778bf952649",
      "fd2dd89a02c845749277122b6b6ff950",
      "069982490a6f40c99dd18422032d2c88",
      "5cb5fa8ce08046aab383a70a67501a4b",
      "d6ecbfe7ee7b4d4da398c5ee56badae9",
      "92f6efa8b5fd49e69bdada865cbc3fab",
      "c6638c5846de4196a0a8238b10db6cdd",
      "88ea6259ff60465884b7d21ee6b48479"
     ]
    },
    "colab_type": "code",
    "id": "DmXFp9NdTdnO",
    "outputId": "3fe93ff7-235f-4f24-92d9-652824ba6089"
   },
   "outputs": [],
   "source": [
    "print(\"Testing your AlexNet architecture: \", verify(test_my_alexnet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "colab_type": "code",
    "id": "CBoLgRrlBpHl",
    "outputId": "03113d70-bde0-4e97-9530-bd3cd8123096"
   },
   "outputs": [],
   "source": [
    "my_alexnet = MyAlexNet()\n",
    "print(my_alexnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J6AYkHAgBpHw"
   },
   "outputs": [],
   "source": [
    "# TODO: add a decent initial setting and tune from there\n",
    "optimizer_config = {\n",
    "  \"optimizer_type\": \"adam\",\n",
    "  \"lr\": 1e-3,\n",
    "  \"weight_decay\": 1e-5\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RihohGnIhaDR"
   },
   "source": [
    "<span style=\"color:red\">TA TODO: corrupt the values above before releasing</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DtCIaTMmBpIK"
   },
   "outputs": [],
   "source": [
    "my_alexnet = MyAlexNet()\n",
    "optimizer = get_optimizer(my_alexnet, optimizer_config)\n",
    "\n",
    "trainer = Trainer(data_dir=data_base_path, \n",
    "                  model = my_alexnet,\n",
    "                  optimizer = optimizer,\n",
    "                  model_dir = os.path.join(model_base_path, 'alexnet'),\n",
    "                  train_data_transforms = get_data_augmentation_transforms(inp_size, dataset_mean, dataset_std),\n",
    "                  test_data_transforms = get_fundamental_transforms(inp_size, dataset_mean, dataset_std),\n",
    "                  batch_size = 32,\n",
    "                  load_from_disk = False,\n",
    "                  cuda = is_cuda\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BOeaVrlZTdnY"
   },
   "source": [
    "The following training cell will take roughly 20 minutes or slightly more using CPU (but possibly under 5 minute using GPU depending on the batch size; the TAs got it within 3 minutes on a GTX1060)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "CAcncwLPBpIQ",
    "outputId": "2c47c01f-ab88-4414-bb0e-cb0ef17ac5fa"
   },
   "outputs": [],
   "source": [
    "trainer.train(num_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ax5cpYmZTdna"
   },
   "source": [
    "Now let's have your model predict on some examples and see how well it performs qualitatively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rc_IeNR9Tdnb"
   },
   "outputs": [],
   "source": [
    "# # visualize train split\n",
    "print(\"Examples from train split:\")\n",
    "visualize(my_alexnet, 'train', get_fundamental_transforms(inp_size, dataset_mean, dataset_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IMxmCz4WTdnc"
   },
   "outputs": [],
   "source": [
    "# # visualize test split\n",
    "print(\"Examples from test split:\")\n",
    "visualize(my_alexnet, 'test', get_fundamental_transforms(inp_size, dataset_mean, dataset_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "colab_type": "code",
    "id": "Cimj95G_BpIU",
    "outputId": "d3a0ae4b-6c7c-4b02-cd45-904edd6f45af",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainer.plot_loss_history()\n",
    "trainer.plot_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qMI3CdEuBpIb",
    "outputId": "ee50a93a-ddad-4114-ed56-eff8f1b16085"
   },
   "outputs": [],
   "source": [
    "train_accuracy = trainer.train_accuracy_history[-1]\n",
    "validation_accuracy = trainer.validation_accuracy_history[-1]\n",
    "print('Train Accuracy = {:.4f}; Validation Accuracy = {:.4f}'.format(train_accuracy, validation_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T6DN_wGXTdni"
   },
   "source": [
    "**TODO 16**: Like both previous sections, you are required to pass a threshold of **85%** for this part. Copy the plots and values onto the report and answer questions accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have completed all the code required for this PS. We hope you enjoyed this course and learnt something useful from this course.\n",
    "\n",
    "Please revisit PS6.pdf and complete the report."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "proj6.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "069982490a6f40c99dd18422032d2c88": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_92f6efa8b5fd49e69bdada865cbc3fab",
      "max": 244418560,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d6ecbfe7ee7b4d4da398c5ee56badae9",
      "value": 244418560
     }
    },
    "0b81f9c1f6bc454a87fe4778bf952649": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_069982490a6f40c99dd18422032d2c88",
       "IPY_MODEL_5cb5fa8ce08046aab383a70a67501a4b"
      ],
      "layout": "IPY_MODEL_fd2dd89a02c845749277122b6b6ff950"
     }
    },
    "5cb5fa8ce08046aab383a70a67501a4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_88ea6259ff60465884b7d21ee6b48479",
      "placeholder": "",
      "style": "IPY_MODEL_c6638c5846de4196a0a8238b10db6cdd",
      "value": " 233M/233M [01:46&lt;00:00, 2.30MB/s]"
     }
    },
    "88ea6259ff60465884b7d21ee6b48479": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "92f6efa8b5fd49e69bdada865cbc3fab": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c6638c5846de4196a0a8238b10db6cdd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d6ecbfe7ee7b4d4da398c5ee56badae9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "fd2dd89a02c845749277122b6b6ff950": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
